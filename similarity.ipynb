{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ed99e2b",
   "metadata": {},
   "source": [
    "# ðŸ§ª Semantic Similarity Testing with Gemini Embeddings\n",
    "\n",
    "This notebook tests the updated `deduplicate.py` with:\n",
    "1. **Generic frame detection** - penalizes minified stacks like `app.js:1`\n",
    "2. **Gemini semantic embeddings** - understands meaning, not just word overlap\n",
    "3. **Error type matching** - penalizes mismatched error types when stack is generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adfb6c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Semantic embeddings enabled: True\n"
     ]
    }
   ],
   "source": [
    "# Setup - Import the updated deduplicate module\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Set your Gemini API key (you can also set it as environment variable)\n",
    "os.environ['GEMINI_API_KEY'] = 'AIzaSyCtu2O_qGF9HsVFD3Alhb20E_ty_w-jWmk'\n",
    "\n",
    "# Import the updated deduplicate module\n",
    "from deduplicate import (\n",
    "    run_pipeline, \n",
    "    USE_SEMANTIC_EMBEDDINGS,\n",
    "    get_frame_quality,\n",
    "    calculate_semantic_similarities\n",
    ")\n",
    "\n",
    "print(f\"âœ… Semantic embeddings enabled: {USE_SEMANTIC_EMBEDDINGS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2970e0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 entries from Veoci\n",
      "Columns: ['json', 'pairedItem']...\n"
     ]
    }
   ],
   "source": [
    "# Load real Veoci entries\n",
    "veoci_entries = pd.read_json('Get_Veoci_Form_Entries.json')\n",
    "print(f\"Loaded {len(veoci_entries)} entries from Veoci\")\n",
    "print(f\"Columns: {list(veoci_entries.columns)[:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f4919c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 213 candidate entries from Veoci JSON\n",
      "\n",
      "Sample entry keys: ['id', 'orgSequenceId', 'objectType', 'container', 'name', 'lastModified', 'properties', 'created']...\n",
      "Sample entry ID: 1580841464\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame to list of dicts for the pipeline\n",
    "# The JSON structure is: {\"json\": {\"entries\": [...]}}\n",
    "if 'json' in veoci_entries.columns and not veoci_entries.empty:\n",
    "    candidates_raw = veoci_entries['json'][0]['entries']\n",
    "    print(f\"Extracted {len(candidates_raw)} candidate entries from Veoci JSON\")\n",
    "else:\n",
    "    candidates_raw = veoci_entries.to_dict('records')\n",
    "    print(f\"Converted {len(candidates_raw)} entries to candidate format\")\n",
    "\n",
    "# Preview a sample entry structure\n",
    "if candidates_raw:\n",
    "    sample = candidates_raw[0]\n",
    "    print(f\"\\nSample entry keys: {list(sample.keys())[:8]}...\")\n",
    "    print(f\"Sample entry ID: {sample.get('id', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e73db7",
   "metadata": {},
   "source": [
    "## ðŸ“ Define Incoming Error to Test\n",
    "\n",
    "Use the same incoming entry from your n8n workflow, or modify it to test different scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bc06931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Incoming Error:\n",
      "   Message: TypeError: undefined is not an object (evaluating 't.address')\n",
      "   Error Type: TypeError\n",
      "   Environment: PROD-MOBILE\n"
     ]
    }
   ],
   "source": [
    "# Real incoming entry from your n8n workflow (modify as needed)\n",
    "incoming_entry_raw = [\n",
    "  {\n",
    "    \"body\": {\n",
    "      \"5\": \"TypeError: undefined is not an object (evaluating 't.address')\",\n",
    "      \"6\": \"/\",\n",
    "      \"8\": \"Stacktrace ionic://localhost/js/app.js:1 - /******/ (function() { // webpackBootstrap src-cordova/www/js/webpack:/node_modules/chart.js/dist/chart.mjs:2726 - if ((reverse && position !== 'right') || (!reverse && position === 'right')) { src-cordova/www/js/webpack:/node_modules/chart.js/dist/chart.mjs:2726\",\n",
    "      \"13\": \"Mozilla/5.0 (iPhone; CPU iPhone OS 18_2 like Mac OS X)\",\n",
    "      \"15\": \"iOS\",\n",
    "      \"16\": \"Mobile Safari UI/WKWebView 18.2\",\n",
    "      \"18\": \"6.0.545322-ios\",\n",
    "      \"21\": \"5f1875273e1741000a1a4a25\",  # Project ID\n",
    "      \"24\": [],\n",
    "      \"25\": \"PROD-MOBILE\",\n",
    "      \"26\": \"veoci-mobile-client\",\n",
    "      \"27\": \"TypeError\",\n",
    "      \"39\": \"https://app.veoci.com/v/c/67813/dashboard\",\n",
    "      \"id\": \"test-incoming-001\",\n",
    "      \"formId\": \"35430484\",\n",
    "      \"name\": \"Test: TypeError address property\"\n",
    "    }\n",
    "  }\n",
    "]\n",
    "\n",
    "print(\"ðŸ“¥ Incoming Error:\")\n",
    "print(f\"   Message: {incoming_entry_raw[0]['body']['5']}\")\n",
    "print(f\"   Error Type: {incoming_entry_raw[0]['body'].get('27', 'Unknown')}\")\n",
    "print(f\"   Environment: {incoming_entry_raw[0]['body'].get('25', 'Unknown')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbd01aa",
   "metadata": {},
   "source": [
    "## ðŸš€ Run the Pipeline with Semantic Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f2caab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â±ï¸  Pipeline completed in 63.49 seconds\n",
      "ðŸ“Š Method used: semantic_embeddings\n",
      "âš ï¸  Generic stack detected: True\n",
      "ðŸ“ˆ Frame quality: low\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Gemini embeddings for message similarity\n"
     ]
    }
   ],
   "source": [
    "# Run the updated pipeline\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "result = run_pipeline(incoming_entry_raw, candidates_raw)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"â±ï¸  Pipeline completed in {elapsed:.2f} seconds\")\n",
    "print(f\"ðŸ“Š Method used: {result.get('metadata', {}).get('similarity_method', 'unknown')}\")\n",
    "print(f\"âš ï¸  Generic stack detected: {result.get('metadata', {}).get('generic_stack_detected', False)}\")\n",
    "print(f\"ðŸ“ˆ Frame quality: {result.get('metadata', {}).get('incoming_frame_quality', 'unknown')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5714e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check if candidates have matching project IDs\n",
    "from deduplicate import normalize_veoci_entry, normalize_incoming_entry, passes_hard_gates\n",
    "\n",
    "incoming_normalized = normalize_incoming_entry(incoming_entry_raw)\n",
    "print(f\"Incoming Project ID: {incoming_normalized.get('project')}\")\n",
    "\n",
    "# Check first few candidates\n",
    "passed_count = 0\n",
    "failed_reasons = []\n",
    "for i, cand in enumerate(candidates_raw[:5]):\n",
    "    cand_normalized = normalize_veoci_entry(cand)\n",
    "    passed, reasons = passes_hard_gates(incoming_normalized, cand_normalized)\n",
    "    print(f\"\\nCandidate {i+1} (ID: {cand_normalized['entry_id']}):\")\n",
    "    print(f\"  Project: {cand_normalized.get('project')}\")\n",
    "    print(f\"  Passed: {passed}\")\n",
    "    if not passed:\n",
    "        print(f\"  Reasons: {reasons}\")\n",
    "        failed_reasons.extend(reasons)\n",
    "    else:\n",
    "        passed_count += 1\n",
    "\n",
    "print(f\"\\nâœ… Passed: {passed_count}/5 candidates checked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4827c5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ“‹ BATCH SUMMARY\n",
      "============================================================\n",
      "Total Analyzed: 1\n",
      "Related Found:  0\n",
      "High Confidence:   0\n",
      "Medium Confidence: 0\n",
      "Low Confidence:    0\n"
     ]
    }
   ],
   "source": [
    "# Display summary\n",
    "summary = result['batchSummary']\n",
    "print(\"=\" * 60)\n",
    "print(\"ðŸ“‹ BATCH SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total Analyzed: {summary['totalAnalyzed']}\")\n",
    "print(f\"Related Found:  {summary['relatedFound']}\")\n",
    "print(f\"High Confidence:   {summary['confidenceCounts']['High']}\")\n",
    "print(f\"Medium Confidence: {summary['confidenceCounts']['Medium']}\")\n",
    "print(f\"Low Confidence:    {summary['confidenceCounts']['Low']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42b1e5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matches found!\n"
     ]
    }
   ],
   "source": [
    "# Display top matches as a DataFrame for easy analysis\n",
    "entries = result['relatedEntries']\n",
    "\n",
    "if entries:\n",
    "    df_results = pd.DataFrame([\n",
    "        {\n",
    "            'Entry ID': e['entryId'],\n",
    "            'Name': e.get('name', '')[:50] + '...' if e.get('name') and len(e.get('name', '')) > 50 else e.get('name', ''),\n",
    "            'Score': f\"{e['score']:.2f}\",\n",
    "            'Confidence': e['confidence'],\n",
    "            'Message Sim': f\"{e['breakdown']['message']:.2f}\",\n",
    "            'Stack Score': e['breakdown']['stack'],\n",
    "            'Signals': ', '.join(e.get('signals', [])),\n",
    "            'Error Type': e.get('errorType', ''),\n",
    "            'Environment': e.get('environment', '')\n",
    "        }\n",
    "        for e in entries[:15]  # Top 15\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nðŸ“Š TOP MATCHES (sorted by score):\\n\")\n",
    "    display(df_results)\n",
    "else:\n",
    "    print(\"No matches found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49787942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸŽ¯ HIGH CONFIDENCE MATCHES - DETAILED VIEW\n",
      "============================================================\n",
      "\n",
      "No high confidence matches found - this is expected with generic stacks!\n"
     ]
    }
   ],
   "source": [
    "# Detailed view of High confidence matches\n",
    "print(\"=\" * 60)\n",
    "print(\"ðŸŽ¯ HIGH CONFIDENCE MATCHES - DETAILED VIEW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "high_confidence = [e for e in entries if e['confidence'] == 'High']\n",
    "\n",
    "for i, entry in enumerate(high_confidence[:5], 1):\n",
    "    print(f\"\\n--- Match #{i} (Score: {entry['score']:.2f}) ---\")\n",
    "    print(f\"Entry ID: {entry['entryId']}\")\n",
    "    print(f\"Name: {entry.get('name', 'N/A')}\")\n",
    "    print(f\"Message Similarity: {entry['breakdown']['message']:.2f}\")\n",
    "    print(f\"Stack Score: {entry['breakdown']['stack']}\")\n",
    "    print(f\"Signals: {', '.join(entry.get('signals', []))}\")\n",
    "    print(f\"Explanation: {entry['explanation'][:150]}...\")\n",
    "    if entry.get('linkedTickets'):\n",
    "        print(f\"ðŸ”— Linked Tickets: {entry['linkedTickets']}\")\n",
    "\n",
    "if not high_confidence:\n",
    "    print(\"\\nNo high confidence matches found - this is expected with generic stacks!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f49a65f",
   "metadata": {},
   "source": [
    "## ðŸ”¬ Compare: Semantic vs TF-IDF Similarity\n",
    "\n",
    "Let's see how Gemini embeddings compare to the old TF-IDF approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b1c3e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¬ SEMANTIC vs TF-IDF COMPARISON\n",
      "======================================================================\n",
      "\n",
      "Incoming: TypeError: Cannot read property 'address' of undefined\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error Message</th>\n",
       "      <th>Semantic (Gemini)</th>\n",
       "      <th>TF-IDF</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TypeError: undefined is not an object (evaluat...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.24</td>\n",
       "      <td>+0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cannot access property 'address' on undefined ...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.41</td>\n",
       "      <td>+0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>null is not an object (evaluating 'this.barCod...</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>+0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Attempted to assign to readonly property</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.07</td>\n",
       "      <td>+0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Error Message Semantic (Gemini) TF-IDF  \\\n",
       "0  TypeError: undefined is not an object (evaluat...              0.93   0.24   \n",
       "1  Cannot access property 'address' on undefined ...              0.96   0.41   \n",
       "2  null is not an object (evaluating 'this.barCod...              0.66   0.00   \n",
       "3           Attempted to assign to readonly property              0.65   0.07   \n",
       "\n",
       "  Difference  \n",
       "0      +0.69  \n",
       "1      +0.55  \n",
       "2      +0.66  \n",
       "3      +0.58  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare semantic understanding on specific error messages\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity as sklearn_cosine\n",
    "\n",
    "test_messages = [\n",
    "    \"TypeError: Cannot read property 'address' of undefined\",  # Incoming\n",
    "    \"TypeError: undefined is not an object (evaluating 't.address')\",  # Same concept\n",
    "    \"Cannot access property 'address' on undefined value\",  # Same concept, different words\n",
    "    \"null is not an object (evaluating 'this.barCodeValue.match')\",  # Different bug\n",
    "    \"Attempted to assign to readonly property\",  # Completely different\n",
    "]\n",
    "\n",
    "print(\"ðŸ”¬ SEMANTIC vs TF-IDF COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nIncoming: {test_messages[0]}\\n\")\n",
    "\n",
    "# Gemini semantic similarities\n",
    "semantic_sims = calculate_semantic_similarities(test_messages[0], test_messages[1:])\n",
    "\n",
    "# TF-IDF similarities\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\")\n",
    "tfidf_matrix = vectorizer.fit_transform(test_messages)\n",
    "tfidf_sims = sklearn_cosine(tfidf_matrix[0:1], tfidf_matrix[1:])[0]\n",
    "\n",
    "# Compare\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Error Message': test_messages[1:],\n",
    "    'Semantic (Gemini)': [f\"{s:.2f}\" for s in semantic_sims],\n",
    "    'TF-IDF': [f\"{s:.2f}\" for s in tfidf_sims],\n",
    "    'Difference': [f\"{semantic_sims[i] - tfidf_sims[i]:+.2f}\" for i in range(len(semantic_sims))]\n",
    "})\n",
    "\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22d20419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ FULL JSON RESULT (for debugging):\n",
      "{\n",
      "  \"batchSummary\": {\n",
      "    \"totalAnalyzed\": 1,\n",
      "    \"relatedFound\": 0,\n",
      "    \"confidenceCounts\": {\n",
      "      \"High\": 0,\n",
      "      \"Medium\": 0,\n",
      "      \"Low\": 0\n",
      "    }\n",
      "  },\n",
      "  \"relatedEntries\": [],\n",
      "  \"metadata\": {\n",
      "    \"similarity_method\": \"semantic_embeddings\",\n",
      "    \"incoming_frame_quality\": \"low\",\n",
      "    \"generic_stack_detected\": true\n",
      "  }\n",
      "}...\n"
     ]
    }
   ],
   "source": [
    "# Output full JSON result for debugging\n",
    "print(\"ðŸ“„ FULL JSON RESULT (for debugging):\")\n",
    "print(json.dumps(result, indent=2, default=str)[:3000] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "152a21c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d4d0b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the local file\n",
    "VeociEntries = pd.read_json('Get_Veoci_Form_Entries.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b6267c",
   "metadata": {},
   "source": [
    "> **Note:** This file simulates Veoci API output and will later be replaced by an HTTP payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df0e9d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "incoming_entry_raw = [\n",
    "  {\n",
    "    \"headers\": {\n",
    "      \"x-forwarded-for\": \"3.208.214.5\",\n",
    "      \"x-forwarded-proto\": \"https\",\n",
    "      \"x-forwarded-port\": \"443\",\n",
    "      \"host\": \"n8n.stg.veoci.com\",\n",
    "      \"x-amzn-trace-id\": \"Root=1-6933355c-32df78546884c9ae2876637f\",\n",
    "      \"content-length\": \"1692\",\n",
    "      \"content-type\": \"application/json; charset=UTF-8\",\n",
    "      \"user-agent\": \"Apache-HttpClient/4.5.13 (Java/21.0.9)\",\n",
    "      \"accept-encoding\": \"gzip,deflate\"\n",
    "    },\n",
    "    \"params\": {},\n",
    "    \"query\": {},\n",
    "    \"body\": {\n",
    "      \"5\": \"Fri Dec 05 2025 14:41:07 GMT-0500 (Eastern Standard Time): User logged out\",\n",
    "      \"6\": \"/\",\n",
    "      \"8\": \"Stacktrace ionic://localhost/js/app.js:1 - /******/ (function() { // webpackBootstrap src-cordova/www/js/webpack:/node_modules/chart.js/dist/chart.mjs:2726 - if ((reverse && position !== 'right') || (!reverse && position === 'right')) { src-cordova/www/js/webpack:/node_modules/chart.js/dist/chart.mjs:2726 - if ((reverse && position !== 'right') || (!reverse && position === 'right')) { src-cordova/www/js/webpack:/node_modules/chart.js/dist/chart.mjs:2758 - titleX = offsetFromEdge(scale, position, offset); src-cordova/www/js/webpack:/node_modules/chart.js/dist/chart.mjs:2758 - titleX = offsetFromEdge(scale, position, offset); src-cordova/www/js/webpack:/node_modules/chart.js/dist/chart.mjs:2758 - titleX = offsetFromEdge(scale, position, offset);\",\n",
    "      \"16\": \"Mobile Safari UI/WKWebView - 18.6.2\",\n",
    "      \"18\": \"6.0.545322-ios - PROD-MOBILE\",\n",
    "      \"21\": \"5f1875273e1741000a1a4a25\",\n",
    "      \"24\": [],\n",
    "      \"25\": \"PROD-MOBILE\",\n",
    "      \"26\": \"veoci-mobile-client\",\n",
    "      \"27\": \"Error\",\n",
    "      \"34\": \"Error ID: 693335535d860bbd20b41487 Error:Fri Dec 05 2025 14:41:07 GMT-0500 (Eastern Standard Time): User logged out Error occurred at: ionic://localhost/js/app.js:1 - /******/ (function() { // webpackBootstrap View error in Bugsnag\",\n",
    "      \"id\": \"1580841464\",\n",
    "      \"formId\": \"35430484\",\n",
    "      \"name\": \"2025-Dec-05 14:41: Bugsnag ( open) -  PROD-MOBILE:Fri Dec 05 2025 14:41:07 GMT-0500 (Eastern Standard Time): User logged out\",\n",
    "      \"lastModified\": \"2025-12-05T19:41:11Z\",\n",
    "      \"created\": \"2025-12-05T19:41:11Z\",\n",
    "      \"containerName\": \"Veoci Ticketing\",\n",
    "      \"containerId\": \"67813\"\n",
    "    },\n",
    "    \"webhookUrl\": \"https://flows.stg.veoci.com/webhook/bugsnag-triage\",\n",
    "    \"executionMode\": \"production\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3647e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# VeociEntries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bc5f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. HELPER FUNCTIONS ---\n",
    "\n",
    "def is_vendor_file(file_path: str) -> bool:\n",
    "    if not file_path: return False\n",
    "    vendor_patterns = [\n",
    "        r\"^node_modules/\", r\"^@vue/\", r\"vuetify/\", r\"core-js\", r\"zone\\.js\",\n",
    "        r\"runtime-core\\.esm-bundler\\.js\", r\"reactivity\\.esm-bundler\\.js\",\n",
    "        r\"proxiedModel\\.mjs\", r\"app\\..*\\.js\", r\"vendor\\..*\\.js\", r\"chunk-.*\\.js\",\n",
    "        r\"LogbackBugsnagAppender\\.java\", r\"AppenderBase\\.java\",\n",
    "        r\"AppenderAttachableImpl\\.java\", r\"Logger\\.java\", r\"ch\\.qos\\.logback\\.\",\n",
    "        r\"org\\.springframework\\.\", r\"org\\.apache\\.commons\\.\", r\"java\\.util\\.\",\n",
    "        r\"javax?\\.\", r\"sun\\.reflect\\.\"\n",
    "    ]\n",
    "    return any(re.search(p, file_path) for p in vendor_patterns)\n",
    "\n",
    "def parse_stack_frames(input_str: Any) -> List[Dict[str, Any]]:\n",
    "    if not input_str or not isinstance(input_str, str): return []\n",
    "    frames = []\n",
    "    seen = set()\n",
    "\n",
    "    # HTML format: <strong>file:line</strong> - code\n",
    "    html_matches = re.findall(r'<strong>(.*?)</strong>', input_str)\n",
    "    for raw in html_matches:\n",
    "        raw = raw.strip()\n",
    "        if raw in seen: continue\n",
    "        seen.add(raw)\n",
    "        \n",
    "        # Handle \"file:line - code\"\n",
    "        parts = raw.split(' - ', 1)\n",
    "        file_line = parts[0]\n",
    "        \n",
    "        last_colon = file_line.rfind(':')\n",
    "        if last_colon == -1: continue\n",
    "        \n",
    "        file_path = file_line[:last_colon]\n",
    "        line_str = file_line[last_colon+1:]\n",
    "        file_name = file_path.split('/')[-1]\n",
    "        \n",
    "        frames.append({\n",
    "            'file': file_name,\n",
    "            'line': int(line_str) if line_str.isdigit() else None,\n",
    "            'vendor': is_vendor_file(file_path),\n",
    "            'full_path': file_path\n",
    "        })\n",
    "\n",
    "    # Fallback: Plain text format\n",
    "    if not frames:\n",
    "        plain_matches = re.findall(r'([\\w@:\\/\\.\\-]+?\\.(?:vue|js|ts|mjs|jsx|tsx|java)):(\\d+)', input_str)\n",
    "        for full_path, line_num in plain_matches:\n",
    "            raw = f\"{full_path}:{line_num}\"\n",
    "            if raw in seen: continue\n",
    "            seen.add(raw)\n",
    "            \n",
    "            file_name = full_path.split('/')[-1]\n",
    "            frames.append({\n",
    "                'file': file_name,\n",
    "                'line': int(line_num),\n",
    "                'vendor': is_vendor_file(full_path),\n",
    "                'full_path': full_path\n",
    "            })\n",
    "            \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0db5c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. NORMALIZATION ---\n",
    "\n",
    "def normalize_veoci_entry(entry: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Extracts fields from Veoci API format (nested in 'values') into Canonical Schema\"\"\"\n",
    "    values = entry.get('values', {})\n",
    "    \n",
    "    def get_val(key):\n",
    "        field = values.get(key, {})\n",
    "        if not field: return None\n",
    "        val = field.get('data', {}).get('value')\n",
    "        if isinstance(val, list): return \", \".join(val) # Handle multi-value\n",
    "        return val\n",
    "\n",
    "    return {\n",
    "        'entry_id': str(entry.get('id')),\n",
    "        'project': get_val('21'),          # Project ID\n",
    "        'release_stage': get_val('25'),    # Release Stage\n",
    "        'app_version': get_val('18'),      # App Version\n",
    "        'timestamp': entry.get('lastModified'), # Using lastModified as timestamp\n",
    "        'error_message': get_val('5'),     # Error message\n",
    "        'stack_frames': parse_stack_frames(get_val('8')), # Stack trace\n",
    "        'name': entry.get('name')          # Keep name for reference\n",
    "    }\n",
    "\n",
    "def normalize_incoming_entry(entry_wrapper: Any) -> Dict[str, Any]:\n",
    "    \"\"\"Extracts fields from the Incoming_entry structure into Canonical Schema\"\"\"\n",
    "    # Incoming_entry is a list containing a dict with 'body'\n",
    "    if isinstance(entry_wrapper, list):\n",
    "        entry = entry_wrapper[0].get('body', {})\n",
    "    else:\n",
    "        entry = entry_wrapper.get('body', {})\n",
    "\n",
    "    return {\n",
    "        'entry_id': str(entry.get('id')),\n",
    "        'project': entry.get('21'),\n",
    "        'release_stage': entry.get('25'),\n",
    "        'app_version': entry.get('18'),\n",
    "        'timestamp': entry.get('lastModified'),\n",
    "        'error_message': entry.get('5'),\n",
    "        'stack_frames': parse_stack_frames(entry.get('8')),\n",
    "        'name': entry.get('name')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c169e357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Incoming Entry: 1580841464\n",
      "Normalized 213 Candidate Entries\n"
     ]
    }
   ],
   "source": [
    "# --- 3. APPLY NORMALIZATION ---\n",
    "\n",
    "# Normalize Incoming Entry\n",
    "incoming_entry = normalize_incoming_entry(incoming_entry_raw)\n",
    "print(f\"Normalized Incoming Entry: {incoming_entry['entry_id']}\")\n",
    "\n",
    "# Normalize Candidate Entries\n",
    "candidate_entries = []\n",
    "if \"json\" in VeociEntries.columns and not VeociEntries.empty:\n",
    "    raw_entries = VeociEntries[\"json\"][0][\"entries\"]\n",
    "    candidate_entries = [normalize_veoci_entry(e) for e in raw_entries]\n",
    "\n",
    "print(f\"Normalized {len(candidate_entries)} Candidate Entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d939dd8c",
   "metadata": {},
   "source": [
    "### Canonical ErrorEntry schema\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"entry_id\": \"str\",\n",
    "  \"project\": \"str\",\n",
    "  \"release_stage\": \"str\",\n",
    "  \"app_version\": \"str\",\n",
    "  \"timestamp\": \"str (ISO8601) or int\",\n",
    "  \"error_message\": \"str\",\n",
    "  \"stack_frames\": [\n",
    "    {\"file\": \"str\", \"line\": \"int\", \"vendor\": \"bool\"}\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cac01ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. HARD GATES ---\n",
    "\n",
    "def passes_hard_gates(incoming: Dict[str, Any], candidate: Dict[str, Any]) -> tuple[bool, List[str]]:\n",
    "    \"\"\"\n",
    "    Returns (passed, reasons)\n",
    "    passed: True if the candidate should be considered for scoring.\n",
    "    reasons: List of reasons for failure (empty if passed).\n",
    "    \"\"\"\n",
    "    reasons = []\n",
    "\n",
    "    # 1. Self-comparison check\n",
    "    if incoming['entry_id'] == candidate['entry_id']:\n",
    "        reasons.append(\"Self-comparison\")\n",
    "\n",
    "    # 2. Project Mismatch (Critical)\n",
    "    if incoming['project'] and candidate['project']:\n",
    "        if incoming['project'] != candidate['project']:\n",
    "            reasons.append(f\"Project mismatch: {incoming['project']} != {candidate['project']}\")\n",
    "            \n",
    "    # 3. Release Stage Mismatch (Optional)\n",
    "    # if incoming['release_stage'] and candidate['release_stage']:\n",
    "    #     if incoming['release_stage'] != candidate['release_stage']:\n",
    "    #         reasons.append(f\"Release stage mismatch: {incoming['release_stage']} != {candidate['release_stage']}\")\n",
    "\n",
    "    return len(reasons) == 0, reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "921faba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. SCORING LOGIC ---\n",
    "\n",
    "def calculate_stack_score(incoming_frames: List[Dict], candidate_frames: List[Dict]) -> Dict[str, Any]:\n",
    "    \"\"\"Computes stack trace similarity score (0-40) and reasons.\"\"\"\n",
    "    score = 0\n",
    "    reasons = []\n",
    "    \n",
    "    # Helper to select top N non-vendor frames\n",
    "    def select_frames(frames):\n",
    "        non_vendor = [f for f in frames if not f['vendor']]\n",
    "        vendor = [f for f in frames if f['vendor']]\n",
    "        chosen = non_vendor if non_vendor else vendor\n",
    "        unique = []\n",
    "        seen = set()\n",
    "        for f in chosen:\n",
    "            if f['file'] not in seen:\n",
    "                seen.add(f['file'])\n",
    "                unique.append(f)\n",
    "            if len(unique) >= (3 if non_vendor else 2): break\n",
    "        return unique\n",
    "\n",
    "    inc_frames = select_frames(incoming_frames)\n",
    "    cand_frames = select_frames(candidate_frames)\n",
    "    \n",
    "    matched_files = set()\n",
    "    \n",
    "    if inc_frames and cand_frames:\n",
    "        # Top frame match (Critical)\n",
    "        if inc_frames[0]['file'] == cand_frames[0]['file']:\n",
    "            score += 25\n",
    "            reasons.append(f\"Top frame match: {inc_frames[0]['file']}\")\n",
    "            matched_files.add(inc_frames[0]['file'])\n",
    "            \n",
    "        # Secondary frame match\n",
    "        if len(inc_frames) > 1 and len(cand_frames) > 1:\n",
    "            if inc_frames[1]['file'] == cand_frames[1]['file']:\n",
    "                score += 10\n",
    "                reasons.append(f\"Secondary frame match: {inc_frames[1]['file']}\")\n",
    "                matched_files.add(inc_frames[1]['file'])\n",
    "                \n",
    "        # Overlap\n",
    "        for f in inc_frames:\n",
    "            for cf in cand_frames:\n",
    "                if f['file'] == cf['file'] and f['file'] not in matched_files:\n",
    "                    score += 5\n",
    "                    reasons.append(f\"Frame overlap: {f['file']}\")\n",
    "                    matched_files.add(f['file'])\n",
    "\n",
    "    return {\"score\": min(score, 40), \"reasons\": reasons}\n",
    "\n",
    "def calculate_time_score(incoming_ts: str, candidate_ts: str) -> Dict[str, Any]:\n",
    "    \"\"\"Computes time decay score (-15 to +5) and reasons.\"\"\"\n",
    "    score = 0\n",
    "    reasons = []\n",
    "    \n",
    "    if incoming_ts and candidate_ts:\n",
    "        try:\n",
    "            dt_inc = pd.to_datetime(incoming_ts)\n",
    "            dt_cand = pd.to_datetime(candidate_ts)\n",
    "            days_diff = abs((dt_inc - dt_cand).days)\n",
    "            \n",
    "            if days_diff <= 7:\n",
    "                score += 5\n",
    "                reasons.append(\"Recent (<= 7 days)\")\n",
    "            \n",
    "            if days_diff > 180: score -= 15\n",
    "            elif days_diff > 90: score -= 8\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    return {\"score\": score, \"reasons\": reasons}\n",
    "\n",
    "def calculate_context_score(incoming: Dict, candidate: Dict) -> Dict[str, Any]:\n",
    "    \"\"\"Computes metadata context score (0-30) and reasons.\"\"\"\n",
    "    score = 0\n",
    "    reasons = []\n",
    "    \n",
    "    if incoming['project'] and candidate['project'] and incoming['project'] == candidate['project']:\n",
    "        score += 15\n",
    "        reasons.append(\"Same Project\")\n",
    "        \n",
    "    if incoming['app_version'] and candidate['app_version'] and incoming['app_version'] == candidate['app_version']:\n",
    "        score += 10\n",
    "        reasons.append(\"Same App Version\")\n",
    "        \n",
    "    if incoming['release_stage'] and candidate['release_stage'] and incoming['release_stage'] == candidate['release_stage']:\n",
    "        score += 5\n",
    "        reasons.append(\"Same Release Stage\")\n",
    "        \n",
    "    return {\"score\": score, \"reasons\": reasons}\n",
    "\n",
    "def calculate_total_score(\n",
    "    incoming: Dict[str, Any], \n",
    "    candidate: Dict[str, Any], \n",
    "    message_similarity: float = 0.0\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Pure function to calculate the total similarity score between an incoming error and a candidate.\n",
    "    Aggregates Stack, Message, Context, and Time scores.\n",
    "    \"\"\"\n",
    "    # 1. Stack Score (0-40)\n",
    "    stack_res = calculate_stack_score(incoming['stack_frames'], candidate['stack_frames'])\n",
    "    stack_score = stack_res['score']\n",
    "    \n",
    "    # 2. Message Score (Raw 0-1 input -> Scaled 0-30)\n",
    "    # We store the RAW score for diagnostics, but use SCALED for total\n",
    "    message_score_scaled = message_similarity * 30\n",
    "    \n",
    "    # 3. Context Score (0-30)\n",
    "    context_res = calculate_context_score(incoming, candidate)\n",
    "    context_score = context_res['score']\n",
    "    \n",
    "    # 4. Time Score (-15 to +5)\n",
    "    time_res = calculate_time_score(incoming['timestamp'], candidate['timestamp'])\n",
    "    time_score = time_res['score']\n",
    "    \n",
    "    # Aggregate\n",
    "    total_score = (\n",
    "        stack_score + \n",
    "        message_score_scaled + \n",
    "        context_score + \n",
    "        time_score\n",
    "    )\n",
    "    \n",
    "    # Cap at 100, Floor at 0\n",
    "    final_score = max(0, min(total_score, 100))\n",
    "    \n",
    "    all_reasons = (\n",
    "        stack_res['reasons'] + \n",
    "        [f\"Message similarity: {message_similarity:.2f}\"] + \n",
    "        context_res['reasons'] + \n",
    "        time_res['reasons']\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"entry_id\": candidate['entry_id'],\n",
    "        \"name\": candidate['name'],\n",
    "        \"final_score\": final_score,\n",
    "        \"scores\": {\n",
    "            \"stack\": stack_score,\n",
    "            \"message\": message_similarity, # Raw 0-1\n",
    "            \"context\": context_score,\n",
    "            \"time\": time_score\n",
    "        },\n",
    "        \"reasons\": all_reasons\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42bf0599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Corpus Size: 213 (1 Incoming + 212 Candidates)\n"
     ]
    }
   ],
   "source": [
    "# --- 6. BUILD TF-IDF CORPUS ---\n",
    "\n",
    "# Build TF-IDF corpus (incoming + gated candidates)\n",
    "corpus = [incoming_entry[\"error_message\"] or \"\"]\n",
    "\n",
    "eligible_candidates = []\n",
    "candidate_index_map = []  # maps TF-IDF index -> candidate index\n",
    "\n",
    "for idx, candidate in enumerate(candidate_entries):\n",
    "    passed, _ = passes_hard_gates(incoming_entry, candidate)\n",
    "    if passed:\n",
    "        corpus.append(candidate[\"error_message\"] or \"\")\n",
    "        eligible_candidates.append(candidate)\n",
    "        candidate_index_map.append(idx)\n",
    "\n",
    "print(f\"TF-IDF Corpus Size: {len(corpus)} (1 Incoming + {len(eligible_candidates)} Candidates)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4aa2ccb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix Shape: (213, 1109)\n"
     ]
    }
   ],
   "source": [
    "# --- 7. FIT TF-IDF ---\n",
    "\n",
    "if len(corpus) > 1:\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words=\"english\",\n",
    "        min_df=1,\n",
    "        max_df=0.95\n",
    "    )\n",
    "\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "    print(\"TF-IDF Matrix Shape:\", tfidf_matrix.shape)\n",
    "else:\n",
    "    print(\"Not enough data for TF-IDF.\")\n",
    "    tfidf_matrix = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a9f8875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed 212 similarity scores.\n"
     ]
    }
   ],
   "source": [
    "# --- 8. COMPUTE COSINE SIMILARITIES ---\n",
    "\n",
    "if tfidf_matrix is not None:\n",
    "    incoming_vector = tfidf_matrix[0]\n",
    "    candidate_vectors = tfidf_matrix[1:]\n",
    "\n",
    "    message_similarities = cosine_similarity(\n",
    "        incoming_vector,\n",
    "        candidate_vectors\n",
    "    )[0]\n",
    "    print(f\"Computed {len(message_similarities)} similarity scores.\")\n",
    "else:\n",
    "    print(\"Skipping TF-IDF computation (no eligible candidates or corpus too small).\")\n",
    "    message_similarities = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104fe53b",
   "metadata": {},
   "source": [
    "### Context score\n",
    "Context score captures metadata alignment (e.g., app version, release stage).\n",
    "- **Range**: 0â€“30\n",
    "- **Weight**: Low (supporting signal only)\n",
    "- **Purpose**: Boosts candidates that match the environment of the incoming error, even if the stack/message match is imperfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48ae30d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Integrated Similarity Pipeline...\n",
      "Found 212 matches.\n"
     ]
    }
   ],
   "source": [
    "# --- 9. EXECUTION PIPELINE (INTEGRATED) ---\n",
    "\n",
    "print(\"Starting Integrated Similarity Pipeline...\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, candidate in enumerate(eligible_candidates):\n",
    "    # Get pre-computed message similarity\n",
    "    raw_msg_sim = message_similarities[i] if i < len(message_similarities) else 0.0\n",
    "    \n",
    "    # Calculate Total Score using the pure function\n",
    "    result = calculate_total_score(incoming_entry, candidate, raw_msg_sim)\n",
    "    \n",
    "    if result['final_score'] > 0:\n",
    "        results.append(result)\n",
    "\n",
    "# Sort and Display\n",
    "results.sort(key=lambda x: x['final_score'], reverse=True)\n",
    "print(f\"Found {len(results)} matches.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "571528fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>final_score</th>\n",
       "      <th>stack_score</th>\n",
       "      <th>message_raw</th>\n",
       "      <th>context_score</th>\n",
       "      <th>time_score</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1577493686</td>\n",
       "      <td>80.549355</td>\n",
       "      <td>35</td>\n",
       "      <td>0.518312</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-Dec-01 21:36: Bugsnag ( open) -  PROD-MOB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1573468818</td>\n",
       "      <td>72.746747</td>\n",
       "      <td>35</td>\n",
       "      <td>0.258225</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-Nov-26 10:22: Bugsnag ( open) -  PROD-MOB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1574883386</td>\n",
       "      <td>66.411104</td>\n",
       "      <td>35</td>\n",
       "      <td>0.047037</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-Nov-28 20:41: Bugsnag ( ignored) -  PROD-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1578456898</td>\n",
       "      <td>65.934662</td>\n",
       "      <td>35</td>\n",
       "      <td>0.031155</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-Dec-03 11:15: Bugsnag ( ignored) -  PROD-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1577908710</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-Dec-02 20:41: Bugsnag ( ignored) -  PROD-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1574414416</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-Nov-28 04:43: Bugsnag ( open) -  PROD-MOB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1530220994</td>\n",
       "      <td>61.269356</td>\n",
       "      <td>35</td>\n",
       "      <td>0.208979</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-Oct-09 06:28: Bugsnag ( open) -  PROD-MOB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1574820389</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-Nov-28 07:55: Bugsnag ( open) -  PROD-MOB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1575214338</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-Nov-29 08:20: Bugsnag ( open) -  PROD-MOB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1537105308</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-Oct-16 13:59: Bugsnag ( fixed) -  PROD-MO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     entry_id  final_score  stack_score  message_raw  context_score  \\\n",
       "0  1577493686    80.549355           35     0.518312             30   \n",
       "1  1573468818    72.746747           35     0.258225             30   \n",
       "2  1574883386    66.411104           35     0.047037             30   \n",
       "3  1578456898    65.934662           35     0.031155             30   \n",
       "4  1577908710    65.000000           35     0.000000             30   \n",
       "5  1574414416    65.000000           35     0.000000             30   \n",
       "6  1530220994    61.269356           35     0.208979             20   \n",
       "7  1574820389    55.000000           25     0.000000             30   \n",
       "8  1575214338    55.000000           25     0.000000             30   \n",
       "9  1537105308    55.000000           35     0.000000             20   \n",
       "\n",
       "   time_score                                               name  \n",
       "0           0  2025-Dec-01 21:36: Bugsnag ( open) -  PROD-MOB...  \n",
       "1           0  2025-Nov-26 10:22: Bugsnag ( open) -  PROD-MOB...  \n",
       "2           0  2025-Nov-28 20:41: Bugsnag ( ignored) -  PROD-...  \n",
       "3           0  2025-Dec-03 11:15: Bugsnag ( ignored) -  PROD-...  \n",
       "4           0  2025-Dec-02 20:41: Bugsnag ( ignored) -  PROD-...  \n",
       "5           0  2025-Nov-28 04:43: Bugsnag ( open) -  PROD-MOB...  \n",
       "6           0  2025-Oct-09 06:28: Bugsnag ( open) -  PROD-MOB...  \n",
       "7           0  2025-Nov-28 07:55: Bugsnag ( open) -  PROD-MOB...  \n",
       "8           0  2025-Nov-29 08:20: Bugsnag ( open) -  PROD-MOB...  \n",
       "9           0  2025-Oct-16 13:59: Bugsnag ( fixed) -  PROD-MO...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 10. SANITY CHECK ---\n",
    "\n",
    "if results:\n",
    "    display_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Flatten scores for display\n",
    "    display_df['stack_score'] = display_df['scores'].apply(lambda x: x['stack'])\n",
    "    display_df['message_raw'] = display_df['scores'].apply(lambda x: x['message']) # Raw 0-1\n",
    "    display_df['context_score'] = display_df['scores'].apply(lambda x: x['context'])\n",
    "    display_df['time_score'] = display_df['scores'].apply(lambda x: x['time'])\n",
    "    \n",
    "    cols = ['entry_id', 'final_score', 'stack_score', 'message_raw', 'context_score', 'time_score', 'name']\n",
    "    display(display_df[cols].head(10))\n",
    "else:\n",
    "    print(\"No matches found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9ec4497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- High Message / Low Stack (Potential Text-Driven Matches) ---\n",
      "Look for: Different errors that happen to have similar words.\n",
      "No significant High Message / Low Stack cases found.\n",
      "\n",
      "--- High Stack / Low Message (Potential Generic Stack Matches) ---\n",
      "Look for: Same error code path, but different error message (e.g. dynamic error strings).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>final_score</th>\n",
       "      <th>stack_score</th>\n",
       "      <th>message_raw</th>\n",
       "      <th>signal_diff</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1574414416</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.875000</td>\n",
       "      <td>2025-Nov-28 04:43: Bugsnag ( open) -  PROD-MOB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1577908710</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.875000</td>\n",
       "      <td>2025-Dec-02 20:41: Bugsnag ( ignored) -  PROD-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1512402078</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.875000</td>\n",
       "      <td>2025-Sep-18 10:46: Bugsnag ( fixed) -  PROD-MO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1321167631</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.875000</td>\n",
       "      <td>2025-Feb-24 07:03: Bugsnag ( fixed) -  PROD-MO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1369970745</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.875000</td>\n",
       "      <td>2025-Apr-16 15:26: Bugsnag ( fixed) -  PROD-MO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1548648440</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>2025-Oct-30 06:14: Bugsnag ( open) -  STAGE-MO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1573468818</td>\n",
       "      <td>72.746747</td>\n",
       "      <td>35</td>\n",
       "      <td>0.258225</td>\n",
       "      <td>-0.616775</td>\n",
       "      <td>2025-Nov-26 10:22: Bugsnag ( open) -  PROD-MOB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1577493686</td>\n",
       "      <td>80.549355</td>\n",
       "      <td>35</td>\n",
       "      <td>0.518312</td>\n",
       "      <td>-0.356688</td>\n",
       "      <td>2025-Dec-01 21:36: Bugsnag ( open) -  PROD-MOB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1561273567</td>\n",
       "      <td>53.183985</td>\n",
       "      <td>25</td>\n",
       "      <td>0.272799</td>\n",
       "      <td>-0.352201</td>\n",
       "      <td>2025-Nov-13 13:54: Bugsnag ( open) -  PROD-MOB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1561273566</td>\n",
       "      <td>53.183985</td>\n",
       "      <td>25</td>\n",
       "      <td>0.272799</td>\n",
       "      <td>-0.352201</td>\n",
       "      <td>2025-Nov-13 13:54: Bugsnag ( open) -  PROD-MOB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       entry_id  final_score  stack_score  message_raw  signal_diff  \\\n",
       "5    1574414416    65.000000           35     0.000000    -0.875000   \n",
       "4    1577908710    65.000000           35     0.000000    -0.875000   \n",
       "13   1512402078    55.000000           35     0.000000    -0.875000   \n",
       "14   1321167631    55.000000           35     0.000000    -0.875000   \n",
       "12   1369970745    55.000000           35     0.000000    -0.875000   \n",
       "..          ...          ...          ...          ...          ...   \n",
       "121  1548648440    40.000000           25     0.000000    -0.625000   \n",
       "1    1573468818    72.746747           35     0.258225    -0.616775   \n",
       "0    1577493686    80.549355           35     0.518312    -0.356688   \n",
       "39   1561273567    53.183985           25     0.272799    -0.352201   \n",
       "40   1561273566    53.183985           25     0.272799    -0.352201   \n",
       "\n",
       "                                                  name  \n",
       "5    2025-Nov-28 04:43: Bugsnag ( open) -  PROD-MOB...  \n",
       "4    2025-Dec-02 20:41: Bugsnag ( ignored) -  PROD-...  \n",
       "13   2025-Sep-18 10:46: Bugsnag ( fixed) -  PROD-MO...  \n",
       "14   2025-Feb-24 07:03: Bugsnag ( fixed) -  PROD-MO...  \n",
       "12   2025-Apr-16 15:26: Bugsnag ( fixed) -  PROD-MO...  \n",
       "..                                                 ...  \n",
       "121  2025-Oct-30 06:14: Bugsnag ( open) -  STAGE-MO...  \n",
       "1    2025-Nov-26 10:22: Bugsnag ( open) -  PROD-MOB...  \n",
       "0    2025-Dec-01 21:36: Bugsnag ( open) -  PROD-MOB...  \n",
       "39   2025-Nov-13 13:54: Bugsnag ( open) -  PROD-MOB...  \n",
       "40   2025-Nov-13 13:54: Bugsnag ( open) -  PROD-MOB...  \n",
       "\n",
       "[120 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 11. SIGNAL DISAGREEMENT ANALYSIS (FALSE POSITIVE REVIEW) ---\n",
    "\n",
    "if results:\n",
    "    analysis_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Normalize scores to 0-1 for comparison\n",
    "    # Stack max = 40, Message max = 1 (raw)\n",
    "    analysis_df['stack_norm'] = analysis_df['scores'].apply(lambda x: x['stack']) / 40.0\n",
    "    analysis_df['message_norm'] = analysis_df['scores'].apply(lambda x: x['message']) \n",
    "    \n",
    "    # Calculate Disagreement (Message - Stack)\n",
    "    # Positive: Message is stronger signal\n",
    "    # Negative: Stack is stronger signal\n",
    "    analysis_df['signal_diff'] = analysis_df['message_norm'] - analysis_df['stack_norm']\n",
    "    \n",
    "    # Prepare display columns\n",
    "    analysis_df['stack_score'] = analysis_df['scores'].apply(lambda x: x['stack'])\n",
    "    analysis_df['message_raw'] = analysis_df['scores'].apply(lambda x: x['message'])\n",
    "    cols = ['entry_id', 'final_score', 'stack_score', 'message_raw', 'signal_diff', 'name']\n",
    "    \n",
    "    print(\"--- High Message / Low Stack (Potential Text-Driven Matches) ---\")\n",
    "    print(\"Look for: Different errors that happen to have similar words.\")\n",
    "    high_msg = analysis_df[analysis_df['signal_diff'] > 0.3].sort_values('signal_diff', ascending=False)\n",
    "    if not high_msg.empty:\n",
    "        display(high_msg[cols].head(5))\n",
    "    else:\n",
    "        print(\"No significant High Message / Low Stack cases found.\")\n",
    "        \n",
    "    print(\"\\n--- High Stack / Low Message (Potential Generic Stack Matches) ---\")\n",
    "    print(\"Look for: Same error code path, but different error message (e.g. dynamic error strings).\")\n",
    "    high_stack = analysis_df[analysis_df['signal_diff'] < -0.3].sort_values('signal_diff', ascending=True)\n",
    "    if not high_stack.empty:\n",
    "        display(high_stack[cols])\n",
    "    else:\n",
    "        print(\"No significant High Stack / Low Message cases found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c53fe23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TRIAGE REPORT (AGENT STYLE) ---\n",
      "{\n",
      "  \"batchSummary\": {\n",
      "    \"totalAnalyzed\": 212,\n",
      "    \"relatedFound\": 212,\n",
      "    \"confidenceCounts\": {\n",
      "      \"High\": 0,\n",
      "      \"Medium\": 2,\n",
      "      \"Low\": 210\n",
      "    }\n",
      "  },\n",
      "  \"relatedEntries\": [\n",
      "    {\n",
      "      \"entryId\": \"1577493686\",\n",
      "      \"score\": 0.8054935456015423,\n",
      "      \"confidence\": \"Medium\",\n",
      "      \"signals\": [\n",
      "        \"stack\",\n",
      "        \"message\",\n",
      "        \"context\",\n",
      "        \"time\"\n",
      "      ],\n",
      "      \"explanation\": \"Match found with Medium confidence (80.5/100). Key signals: Top frame match: app.js; Secondary frame match: chart.mjs; Message similarity: 0.52.\",\n",
      "      \"breakdown\": {\n",
      "        \"stack\": 35,\n",
      "        \"message\": 0.5183118186718078,\n",
      "        \"context\": 30,\n",
      "        \"time\": 0\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"entryId\": \"1573468818\",\n",
      "      \"score\": 0.7274674666421115,\n",
      "      \"confidence\": \"Medium\",\n",
      "      \"signals\": [\n",
      "        \"stack\",\n",
      "        \"message\",\n",
      "        \"context\",\n",
      "        \"time\"\n",
      "      ],\n",
      "      \"explanation\": \"Match found with Medium confidence (72.7/100). Key signals: Top frame match: app.js; Secondary frame match: chart.mjs; Message similarity: 0.26.\",\n",
      "      \"breakdown\": {\n",
      "        \"stack\": 35,\n",
      "        \"message\": 0.2582248888070379,\n",
      "        \"context\": 30,\n",
      "        \"time\": 0\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# --- 12. GENERATE TRIAGE REPORT (AGENT-STYLE) ---\n",
    "import json\n",
    "\n",
    "def generate_triage_report(results: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generates a report similar to the Bugsnag Triage Agent's output.\n",
    "    \"\"\"\n",
    "    \n",
    "    report = {\n",
    "        \"batchSummary\": {\n",
    "            \"totalAnalyzed\": len(eligible_candidates),\n",
    "            \"relatedFound\": len(results),\n",
    "            \"confidenceCounts\": {\"High\": 0, \"Medium\": 0, \"Low\": 0}\n",
    "        },\n",
    "        \"relatedEntries\": []\n",
    "    }\n",
    "    \n",
    "    for res in results:\n",
    "        # Map 0-100 score to Confidence\n",
    "        score = res['final_score']\n",
    "        if score >= 85: confidence = \"High\"\n",
    "        elif score >= 70: confidence = \"Medium\"\n",
    "        else: confidence = \"Low\"\n",
    "        \n",
    "        report[\"batchSummary\"][\"confidenceCounts\"][confidence] += 1\n",
    "        \n",
    "        # Generate Explanation from Reasons\n",
    "        explanation = f\"Match found with {confidence} confidence ({score:.1f}/100). \"\n",
    "        explanation += \"Key signals: \" + \"; \".join(res['reasons'][:3]) + \".\"\n",
    "        \n",
    "        entry = {\n",
    "            \"entryId\": res['entry_id'],\n",
    "            \"score\": score / 100.0, # Normalize to 0-1 for compatibility\n",
    "            \"confidence\": confidence,\n",
    "            \"signals\": list(res['scores'].keys()),\n",
    "            \"explanation\": explanation,\n",
    "            \"breakdown\": res['scores']\n",
    "        }\n",
    "        report[\"relatedEntries\"].append(entry)\n",
    "        \n",
    "    return report\n",
    "\n",
    "# Generate and Display Report\n",
    "triage_report = generate_triage_report(results)\n",
    "\n",
    "print(\"--- TRIAGE REPORT (AGENT STYLE) ---\")\n",
    "# Print only the first 2 entries to avoid token limits\n",
    "short_report = triage_report.copy()\n",
    "short_report['relatedEntries'] = short_report['relatedEntries'][:2]\n",
    "print(json.dumps(short_report, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280277eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63704a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
